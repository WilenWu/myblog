---
title: æœºå™¨å­¦ä¹ (V)--æ— ç›‘ç£å­¦ä¹ (ä¸‰)EMç®—æ³•
categories:
  - Artificial Intelligence
  - Machine Learning
tags:
  - æœºå™¨å­¦ä¹ 
  - æ— ç›‘ç£å­¦ä¹ 
cover: /img/ML-unsupervised-learning.png
top_img: /img/artificial-intelligence.jpg
abbrlink: 4f81b9fa
date: 2024-07-09 20:47:30
description:
katex: true
---

# EMç®—æ³•


## æå¤§ä¼¼ç„¶ä¼°è®¡

**æå¤§ä¼¼ç„¶ä¼°è®¡**ï¼š(maximum likelihood estimate, MLE)  æ˜¯ä¸€ç§å¸¸ç”¨çš„æ¨¡å‹å‚æ•°ä¼°è®¡æ–¹æ³•ã€‚å®ƒå‡è®¾è§‚æµ‹æ ·æœ¬å‡ºç°çš„æ¦‚ç‡æœ€å¤§ï¼Œä¹Ÿå³æ ·æœ¬è”åˆæ¦‚ç‡ï¼ˆä¹Ÿç§°ä¼¼ç„¶å‡½æ•°ï¼‰å–å¾—æœ€å¤§å€¼ã€‚

ä¸ºæ±‚è§£æ–¹ä¾¿ï¼Œå¯¹æ ·æœ¬è”åˆæ¦‚ç‡å–å¯¹æ•°ä¼¼ç„¶å‡½æ•°
$$
\log L(\theta) =\log\mathbb P(X|\theta)=\sum_{i=1}^N\log \mathbb P(\mathbf x_i|\theta)
$$
ä¼˜åŒ–ç›®æ ‡æ˜¯æœ€å¤§åŒ–å¯¹æ•°ä¼¼ç„¶å‡½æ•°
$$
\hat\theta=\arg\max_{\theta}\sum_{i=1}^N\log \mathbb P(\mathbf x_i|\theta)
$$

å‡è®¾ç“œç”°é‡Œæœ‰ä¸¤ç§ç±»å‹çš„è¥¿ç“œğŸ‰ï¼Œç“œå†œéšæœºæŠ½å–äº†10ä¸ªè¥¿ç“œï¼Œæ¥äº†è§£è¥¿ç“œçš„é‡é‡åˆ†å¸ƒ $p(x|\theta)$ï¼Œè®°å½•ç»“æœå¦‚ä¸‹ï¼š

| å˜é‡         | æ ·æœ¬                                              |
| :----------- | :------------------------------------------------ |
| è¥¿ç“œé‡é‡ $x$ | 5.3 , 5.7, 4.7, 4.3, 3.2, 4.9, 4.1, 3.5, 3.8, 1.7 |
| è¥¿ç“œå“ç§ $z$ | 1, 1, 1, 1, 2, 2, 2, 2, 2, 2                      |

<img src="https://warehouse-1310574346.cos.ap-shanghai.myqcloud.com/images/ML/GMM_example.png"  />

å…¶ä¸­ï¼Œè¥¿ç“œçš„å“ç§ $z$ æ˜¯ç¦»æ•£åˆ†å¸ƒ $\mathbb P(z=k)=\pi_k$ï¼Œä¸€èˆ¬å‡è®¾ä¸¤ç§ç±»å‹çš„è¥¿ç“œæœä»å‡å€¼å’Œæ–¹å·®ä¸åŒçš„é«˜æ–¯åˆ†å¸ƒ $N(\mu_1,\sigma^2_1)$å’Œ $N(\mu_2,\sigma^2_2)$ã€‚ç”±å…¨æ¦‚ç‡å…¬å¼ï¼Œè¥¿ç“œé‡é‡çš„æ¦‚ç‡å¯†åº¦æ¨¡å‹
$$
p(x;\theta)=\pi_1\mathcal N(x;\mu_1,\sigma^2_1)+\pi_2\mathcal N(x;\mu_2,\sigma^2_2)
$$

æˆ‘ä»¬å°è¯•ç”¨æå¤§ä¼¼ç„¶ä¼°è®¡æ±‚è§£å‚æ•°$\theta=(\pi_1,\pi_2,\mu_1,\sigma^2_1,\mu_2,\sigma^2_2)$ã€‚

ä¼˜åŒ–ç›®æ ‡å‡½æ•°
$$
\max_{\theta}\sum_{z_i=1}\log \pi_1\mathcal N(x_i;\mu_1,\sigma_1^2)+\sum_{z_i=2}\log \pi_2\mathcal N(x_i;\mu_2,\sigma_2^2) \\
\text{s.t. } \pi_1+\pi_2=1
$$
ä½¿ç”¨æ‹‰æ ¼æœ—æ—¥ä¹˜å­æ³•å®¹æ˜“æ±‚å¾—
$$
\pi_1=0.4,\quad \pi_2=0.6 \\
\mu_1=5,\quad \sigma_1^2=0.54^2 \\
\mu_2=3.53,\quad \sigma_2^2=0.98^2 \\
$$

æœ€ç»ˆå¾—åˆ°

$$
p(x)=0.4\times\mathcal N(x;5,0.54^2)+0.6\times\mathcal N(x;3.53,0.98^2)
$$


ä½†æ˜¯ï¼Œå®é™…ä¸­å¦‚æœç“œå†œæ— æ³•è¾©è¯†æ ‡è®°è¥¿ç“œçš„å“ç§ï¼Œæ­¤æ—¶æ¦‚ç‡åˆ†å¸ƒå‡½æ•°å˜ä¸º
$$
p(x;\theta)=\pi\mathcal N(x;\mu_1,\sigma^2_1)+(1-\pi)\mathcal N(x;\mu_2,\sigma^2_2)
$$

å…¶ä¸­å“ç§$z$ æˆä¸ºéšè—å˜é‡ã€‚å¯¹æ•°ä¼¼ç„¶å‡½æ•°å˜ä¸º
$$
\log L(\theta)=\sum_{i}\log (\pi\mathcal N(x_i;\mu_1,\sigma^2_1)+(1-\pi)\mathcal N(x_i;\mu_2,\sigma^2_2))
$$
å…¶ä¸­å‚æ•° $\theta=(\pi,\mu_1,\sigma^2_1,\mu_2,\sigma^2_2)$ã€‚ä¸Šå¼ä¸­å­˜åœ¨"å’Œçš„å¯¹æ•°"ï¼Œè‹¥ç›´æ¥æ±‚å¯¼å°†ä¼šå˜å¾—å¾ˆéº»çƒ¦ã€‚ä¸‹èŠ‚æˆ‘ä»¬å°†ä¼šä»‹ç»EMç®—æ³•æ¥è§£å†³æ­¤ç±»é—®é¢˜ã€‚

## åŸºæœ¬æ€æƒ³
æ¦‚ç‡æ¨¡å‹æœ‰æ—¶æ—¢å«æœ‰è§‚æµ‹å˜é‡ (observable variable)ï¼Œåˆå«æœ‰éšå˜é‡ (latent variable)ã€‚EMï¼ˆExpectation-Maximizationï¼ŒæœŸæœ›æœ€å¤§ç®—æ³•ï¼‰æ˜¯ä¸€ç§è¿­ä»£ç®—æ³•ï¼Œç”¨äºå«æœ‰éšå˜é‡çš„æ¦‚ç‡æ¨¡å‹çš„æå¤§ä¼¼ç„¶ä¼°è®¡æˆ–æå¤§åéªŒä¼°è®¡ï¼Œæ˜¯æ•°æ®æŒ–æ˜çš„åå¤§ç»å…¸ç®—æ³•ä¹‹ä¸€ã€‚

å‡è®¾ç°æœ‰ä¸€æ‰¹ç‹¬ç«‹åŒåˆ†å¸ƒçš„æ ·æœ¬
$$
X=\{x_1,x_2,\cdots,x_N\}
$$
å®ƒä»¬æ˜¯ç”±æŸä¸ªå«æœ‰éšå˜é‡çš„æ¦‚ç‡åˆ†å¸ƒ $p(x,z|\theta)$ ç”Ÿæˆã€‚è®¾æ ·æœ¬å¯¹åº”çš„éšå˜é‡æ•°æ®
$$
Z=\{z_1,z_2,\cdots,z_N\}
$$

å¯¹äºä¸€ä¸ªå«æœ‰éšå˜é‡ $Z$ çš„æ¦‚ç‡æ¨¡å‹ï¼Œä¸€èˆ¬å°†  $(X,Z)$ ç§°ä¸ºå®Œå…¨æ•°æ® (complete-data)ï¼Œè€Œè§‚æµ‹æ•°æ® $X$ ä¸ºä¸å®Œå…¨æ•°æ®(incomplete-data)ã€‚

å‡è®¾è§‚æµ‹æ•°æ® $X$ æ¦‚ç‡å¯†åº¦å‡½æ•°æ˜¯$p(X|\theta)$ï¼Œå…¶ä¸­$\theta$æ˜¯éœ€è¦ä¼°è®¡çš„æ¨¡å‹å‚æ•°ï¼Œç°å°è¯•ç”¨æå¤§ä¼¼ç„¶ä¼°è®¡æ³•ä¼°è®¡æ­¤æ¦‚ç‡åˆ†å¸ƒçš„å‚æ•°ã€‚ä¸ºäº†ä¾¿äºè®¨è®ºï¼Œæ­¤å¤„å‡è®¾ $z$ ä¸ºè¿ç»­å‹éšæœºå˜é‡ï¼Œåˆ™å¯¹æ•°ä¼¼ç„¶å‡½æ•°ä¸º
$$
\log L(\theta)=\sum_{i=1}^N\log p(x_i|\theta)=\sum_{i=1}^N\log\int_{z_i}p(x_i,z_i|\theta)\mathrm dz_i
$$

  > Suppose you have a probability model with parameters $\theta$.
  > $p(x|\theta)$ has two names. It can be called the **probability of $x$** (given $\theta$), or the **likelihood of $\theta$** (given that $x$  was observed).

æˆ‘ä»¬çš„ç›®æ ‡æ˜¯æå¤§åŒ–è§‚æµ‹æ•°æ® $X$ å…³äºå‚æ•°  $\theta$ çš„å¯¹æ•°ä¼¼ç„¶å‡½æ•°
$$
\hat\theta=\arg\max_{\theta}\log L(\theta)
$$

æ˜¾ç„¶ï¼Œæ­¤æ—¶ $\log L(\theta)$ é‡Œå«æœ‰æœªçŸ¥çš„éšå˜é‡ $z$ ä»¥åŠæ±‚å’Œé¡¹çš„å¯¹æ•°ï¼Œç›¸æ¯”äºä¸å«éšå˜é‡çš„å¯¹æ•°ä¼¼ç„¶å‡½æ•°ï¼Œè¯¥ä¼¼ç„¶å‡½æ•°çš„æå¤§å€¼ç‚¹è¾ƒéš¾æ±‚è§£ï¼Œè€Œ EM ç®—æ³•åˆ™ç»™å‡ºäº†ä¸€ç§è¿­ä»£çš„æ–¹æ³•æ¥å®Œæˆå¯¹ $\log L(\theta)$ çš„æå¤§åŒ–ã€‚

æ³¨æ„ï¼šç¡®å®šå¥½å«éšå˜é‡çš„æ¨¡å‹åï¼Œå³ç¡®å®šäº†è”åˆæ¦‚ç‡å¯†åº¦å‡½æ•° $p(x,z|\theta)$  ï¼Œå…¶ä¸­$\theta$æ˜¯éœ€è¦ä¼°è®¡çš„æ¨¡å‹å‚æ•°ã€‚ä¸ºä¾¿äºè®¨è®ºï¼Œåœ¨æ­¤æœ‰å¿…è¦è¯´æ˜ä¸‹å…¶ä»–å·²çŸ¥çš„æ¦‚ç‡å‡½æ•°ã€‚

è”åˆæ¦‚ç‡å¯†åº¦å‡½æ•°
$$
p(x,z|\theta)=f(x,z;\theta)
$$
è§‚æµ‹å˜é‡ $x$ çš„æ¦‚ç‡å¯†åº¦å‡½æ•°
$$
p(x|\theta)=\int_z f(x,z;\theta)\mathrm dz
$$
éšå˜é‡ $z$ çš„æ¦‚ç‡å¯†åº¦å‡½æ•°
$$
p(z|\theta)=\int_x f(x,z;\theta)\mathrm dx
$$
æ¡ä»¶æ¦‚ç‡å¯†åº¦å‡½æ•°
$$
p(x|z,\theta)=\frac{p(x,z|\theta)}{p(z|\theta)}=\frac{f(x,z;\theta)}{\int_x f(x,z;\theta)\mathrm dx}
$$
å’Œ
$$
p(z|x,\theta)=\frac{p(x,z|\theta)}{p(x|\theta)}=\frac{f(x,z;\theta)}{\int_z f(x,z;\theta)\mathrm dz}
$$
ä¸‹é¢ç»™å‡ºä¸¤ç§æ¨å¯¼æ–¹æ³•ï¼šä¸€ç§å€ŸåŠ© Jensen ä¸ç­‰å¼ï¼›ä¸€ç§ä½¿ç”¨ KL æ•£åº¦ã€‚

**é¦–å…ˆä½¿ç”¨ Jensen ä¸ç­‰å¼æ¨å¯¼**ï¼šä½¿ç”¨å«æœ‰éšå˜é‡çš„å…¨æ¦‚ç‡å…¬å¼
$$
\begin{aligned}
\log p(x_i|\theta)&=\log\int_{z_i} p(x_i,z_i|\theta)\mathrm dz_i \\
&=\log\int_{z_i}q_i(z_i)\frac{p(x_i,z_i|\theta)}{q_i(z_i)}\mathrm dz_i \\
&=\log\mathbb E_z\left(\frac{p(x_i,z_i|\theta)}{q_i(z_i)}\right) \\
&\geqslant \mathbb E_z\left(\log\frac{p(x_i,z_i|\theta)}{q_i(z_i)}\right) \\
&= \int_{z_i}q_i(z_i) \log\frac{p(x_i,z_i|\theta)}{q_i(z_i)}\mathrm dz_i
\end{aligned}
$$
å…¶ä¸­ $q_i(z_i)$ æ˜¯å¼•å…¥çš„ç¬¬$i$ä¸ªæ ·æœ¬==éšå˜é‡$z_i$ çš„ä»»æ„æ¦‚ç‡å¯†åº¦å‡½æ•°ï¼ˆæœªçŸ¥å‡½æ•°ï¼‰==ï¼Œå…¶å® $q$ ä¸ç®¡æ˜¯ä»»æ„å‡½æ•°ï¼Œä¸Šå¼éƒ½æˆç«‹ã€‚ä»åç»­æ¨å¯¼å¾—çŸ¥ï¼Œå½“ $q_i(z_i)$ æ˜¯ $z_i$ çš„æ¦‚ç‡å¯†åº¦æ—¶ï¼Œæ–¹ä¾¿è®¡ç®—ã€‚

æ‰€ä»¥
$$
\log L(\theta)=\sum_{i=1}^N\log p(x_i|\theta)\geqslant B(q,\theta)=\sum_{i=1}^N\int_{z_i}q_i(z_i) \log\frac{p(x_i,z_i|\theta)}{q_i(z_i)}\mathrm dz_i
$$

å…¶ä¸­å‡½æ•° $B$ ä¸ºå¯¹æ•°ä¼¼ç„¶çš„ä¸‹ç•Œå‡½æ•°ã€‚ä¸‹ç•Œæ¯”è¾ƒå¥½æ±‚ï¼Œæ‰€ä»¥æˆ‘ä»¬è¦ä¼˜åŒ–è¿™ä¸ªä¸‹ç•Œæ¥ä½¿å¾—ä¼¼ç„¶å‡½æ•°æœ€å¤§ã€‚

å‡è®¾ç¬¬ $t$ æ¬¡è¿­ä»£æ—¶ $\theta$ çš„ä¼°è®¡å€¼æ˜¯ $\theta^{(t)}$ï¼Œæˆ‘ä»¬å¸Œæœ›ç¬¬ $t+1$ æ¬¡è¿­ä»£æ—¶çš„ $\theta$ èƒ½ä½¿ $\log L(\theta)$ å¢å¤§ï¼Œå³ 
$$
\log L(\theta^{(t)}) \leqslant \log L(\theta^{(t+1)})
$$

å¯ä»¥åˆ†ä¸ºä¸¤æ­¥å®ç°ï¼š

- é¦–å…ˆï¼Œå›ºå®š$\theta=\theta^{(t)}$ ï¼Œé€šè¿‡è°ƒæ•´ $q$ å‡½æ•°ä½¿å¾— $B(q^{(t)},\theta)$ åœ¨ $\theta^{(t)}$ å¤„å’Œ $\log L(\theta^{(t)})$ ç›¸ç­‰ï¼›
  $$
  B(q^{(t)},\theta^{(t)})=\log L(\theta^{(t)})
  $$

- ç„¶åï¼Œå›ºå®š$q$ï¼Œä¼˜åŒ– $\theta^{(t+1)}$ å–åˆ°ä¸‹ç•Œå‡½æ•° $B(q^{(t)},\theta)$ çš„æœ€å¤§å€¼ã€‚
  $$
  \theta^{(t+1)}=\arg\max_{\theta} B(q^{(t)},\theta)
  $$

æ‰€ä»¥
$$
\log L(\theta^{(t+1)})\geqslant B(q^{(t)},\theta^{(t+1)})\geqslant B(q^{(t)},\theta^{(t)})=\log L(\theta^{(t)})
$$

<img src="https://warehouse-1310574346.cos.ap-shanghai.myqcloud.com/images/ML/M-step.png"  />

å› æ­¤ï¼ŒEMç®—æ³•ä¹Ÿå¯ä»¥çœ‹ä½œä¸€ç§åæ ‡æå‡ç®—æ³•ï¼Œé¦–å…ˆå›ºå®šä¸€ä¸ªå€¼ï¼Œå¯¹å¦å¤–ä¸€ä¸ªå€¼æ±‚æå€¼ï¼Œä¸æ–­é‡å¤ç›´åˆ°æ”¶æ•›ã€‚

<img src="https://warehouse-1310574346.cos.ap-shanghai.myqcloud.com/images/ML/Coordinate_Descent.svg" style="zoom: 80%;" />

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å¼€å§‹æ±‚è§£ $q^{(t)}$ ã€‚Jensenä¸ç­‰å¼ä¸­ç­‰å·æˆç«‹çš„æ¡ä»¶æ˜¯è‡ªå˜é‡æ˜¯å¸¸æ•°ï¼Œå³
$$
\frac{p(x_i,z_i|\theta)}{q_i(z_i)}=c
$$
ç”±äºå‡è®¾ $q_i(z_i)$æ˜¯ $z_i$ çš„æ¦‚ç‡å¯†åº¦å‡½æ•°ï¼Œæ‰€ä»¥
$$
p(x_i|\theta)=\int_{z_i}p(x_i,z_i|\theta)\mathrm dz_i=\int_{z_i} cq_i(z_i)\mathrm dz_i=c
$$

äºæ˜¯
$$
q_i(z_i)=\frac{p(x_i,z_i|\theta)}{c}=\frac{p(x_i,z_i|\theta)}{p(x_i|\theta)}=p(z_i|x_i,\theta)
$$
å¯ä»¥çœ‹åˆ°ï¼Œå‡½æ•° $q_i(z_i)$ ä»£è¡¨ç¬¬ $i$ ä¸ªæ•°æ®æ˜¯ $z_i$ çš„æ¦‚ç‡å¯†åº¦ï¼Œæ˜¯å¯ä»¥ç›´æ¥è®¡ç®—çš„ã€‚

æœ€ç»ˆï¼Œæˆ‘ä»¬åªè¦åˆå§‹åŒ–æˆ–ä½¿ç”¨ä¸Šä¸€æ­¥å·²ç»å›ºå®šçš„ $\theta^{(t)}$ï¼Œç„¶åè®¡ç®—
$$
\begin{aligned}
\theta^{(t+1)}& = \arg\max_{\theta}\sum_{i=1}^N\int_{z_i}p(z_i|x_i,\theta^{(t)}) \log\frac{p(x_i,z_i|\theta)}{p(z_i|x_i,\theta^{(t)})}\mathrm dz_i \\
& = \arg\max_{\theta}\sum_{i=1}^N\int_{z_i}p(z_i|x_i,\theta^{(t)}) \log p(x_i,z_i|\theta)\mathrm dz_i \\
& = \arg\max_{\theta}\sum_{i=1}^N \mathbb E_{z_i|x_i,\theta^{(t)}}[\log p(x_i,z_i|\theta)] \\
& = \arg\max_{\theta} Q(\theta,\theta^{(t)})
\end{aligned}
$$

**æ¥ä¸‹æ¥ä½¿ç”¨ KL æ•£åº¦æ¨å¯¼**ï¼šä½¿ç”¨å«æœ‰éšå˜é‡çš„æ¡ä»¶æ¦‚ç‡
$$
\begin{aligned}
\log p(x_i|\theta)&=\log\frac{p(x_i,z_i|\theta)}{p(z_i|x_i,\theta)} \\
&=\int_{z_i}q_i(z_i)\log\frac{p(x_i,z_i|\theta)}{p(z_i|x_i,\theta)}\cdot\frac{q_i(z_i)}{q_i(z_i)}\mathrm dz_i \\
&= \int_{z_i}q_i(z_i) \log\frac{p(x_i,z_i|\theta)}{q_i(z_i)}\mathrm dz_i + \int_{z_i}q_i(z_i) \log\frac{q_i(z_i)}{p(z_i|x_i,\theta)}\mathrm dz_i \\
&=B(q_i,\theta)+KL(q_i\|p_i)
\end{aligned}
$$
åŒæ · $q_i(z_i)$ æ˜¯å¼•å…¥çš„==å…³äº $z_i$ çš„ä»»æ„æ¦‚ç‡å¯†åº¦å‡½æ•°ï¼ˆæœªçŸ¥å‡½æ•°ï¼‰==ï¼Œå‡½æ•° $B(q_i,\theta)$ è¡¨ç¤ºå¯¹æ•°ä¼¼ç„¶çš„ä¸€ä¸ªä¸‹ç•Œï¼Œæ•£åº¦ $KL(q_i\|p_i)$æè¿°äº†ä¸‹ç•Œä¸å¯¹æ•°ä¼¼ç„¶çš„å·®è·ã€‚

åŒæ ·ä¸ºäº†ä¿è¯
$$
\log L(\theta^{(t)}) \leqslant \log L(\theta^{(t+1)})
$$

åˆ†ä¸ºä¸¤æ­¥å®ç°ï¼š

- é¦–å…ˆï¼Œå›ºå®š$\theta=\theta^{(t)}$ ï¼Œé€šè¿‡è°ƒæ•´ $q$ å‡½æ•°ä½¿å¾— $B(q^{(t)},\theta)$ åœ¨ $\theta^{(t)}$ å¤„å’Œ $\log L(\theta^{(t)})$ ç›¸ç­‰ï¼Œå³ $KL(q_i\|p_i)=0$ï¼Œäºæ˜¯
  $$
  q_i(z_i)=p(z_i|x_i,\theta^{(t)})
  $$

- ç„¶åï¼Œå›ºå®š$q$ï¼Œä¼˜åŒ– $\theta^{(t+1)}$ å–åˆ°ä¸‹ç•Œå‡½æ•° $B(q^{(t)},\theta)$ çš„æœ€å¤§å€¼ã€‚
  $$
  \theta^{(t+1)}=\arg\max_{\theta} B(q^{(t)},\theta)
  $$

## ç®—æ³•æµç¨‹

è¾“å…¥ï¼šè§‚æµ‹æ•°æ® $X$ï¼Œè”åˆåˆ†å¸ƒ $p(x,z;\theta)$ï¼Œæ¡ä»¶åˆ†å¸ƒ$P(z|x,\theta)$

è¾“å‡ºï¼šæ¨¡å‹å‚æ•°$\theta$

EMç®—æ³•é€šè¿‡å¼•å…¥éšå«å˜é‡ï¼Œä½¿ç”¨æå¤§ä¼¼ç„¶ä¼°è®¡ï¼ˆMLEï¼‰è¿›è¡Œè¿­ä»£æ±‚è§£å‚æ•°ã€‚æ¯æ¬¡è¿­ä»£ç”±ä¸¤æ­¥ç»„æˆï¼š

- **E-step**ï¼šæ±‚æœŸæœ› (expectation)ã€‚ä»¥å‚æ•°çš„åˆå§‹å€¼æˆ–ä¸Šä¸€æ¬¡è¿­ä»£çš„æ¨¡å‹å‚æ•° $\theta^{(t)}$ æ¥è®¡ç®—éšå˜é‡åéªŒæ¦‚ç‡ $p(z_i|x_i,\theta^{(t)})$ ï¼Œå¹¶è®¡ç®—æœŸæœ›(expectation)
  $$
  Q(\theta,\theta^{(t)})=\sum_{i=1}^N\int_{z_i}p(z_i|x_i,\theta^{(t)}) \log p(x_i,z_i|\theta)\mathrm dz_i
  $$

- **M-step**: æ±‚æå¤§ (maximization)ï¼Œæå¤§åŒ–Eæ­¥ä¸­çš„æœŸæœ›å€¼ï¼Œæ¥ç¡®å®š $t+1$ æ¬¡è¿­ä»£çš„å‚æ•°ä¼°è®¡å€¼
  $$
  \theta^{(t+1)}=\arg\max_{\theta} Q(\theta,\theta^{(t)})
  $$

ä¾æ¬¡è¿­ä»£ï¼Œç›´è‡³æ”¶æ•›åˆ°å±€éƒ¨æœ€ä¼˜è§£ã€‚

# é«˜æ–¯æ··åˆæ¨¡å‹

## åŸºç¡€æ¨¡å‹

é«˜æ–¯æ··åˆæ¨¡å‹ (Gaussian Mixture Model, GMM) æ•°æ®å¯ä»¥çœ‹ä½œæ˜¯ä»$K$ä¸ªé«˜æ–¯åˆ†å¸ƒä¸­ç”Ÿæˆå‡ºæ¥çš„ï¼Œæ¯ä¸ªé«˜æ–¯åˆ†å¸ƒç§°ä¸ºä¸€ä¸ªç»„ä»¶ (Component)ã€‚

å¼•å…¥éšå˜é‡ $z\in\{1,2,\cdots,K\}$ï¼Œè¡¨ç¤ºå¯¹åº”çš„æ ·æœ¬ $x$ å±äºå“ªä¸€ä¸ªé«˜æ–¯åˆ†å¸ƒï¼Œè¿™ä¸ªå˜é‡æ˜¯ä¸€ä¸ªç¦»æ•£çš„éšæœºå˜é‡ï¼š
$$
\mathbb P(z=k)=\pi_k \\
\text{s.t. } \sum_{k=1}^K\pi_k=1
$$
å¯å°† $\pi_k$ è§†ä¸ºé€‰æ‹©ç¬¬ $k$ é«˜æ–¯åˆ†å¸ƒçš„å…ˆéªŒæ¦‚ç‡ï¼Œè€Œå¯¹åº”çš„ç¬¬$k$ ä¸ªé«˜æ–¯åˆ†å¸ƒçš„æ ·æœ¬æ¦‚ç‡
$$
p(x|z=k)=\mathcal N(x;\mu_k,\Sigma_k)
$$

äºæ˜¯é«˜æ–¯æ··åˆæ¨¡å‹
$$
p_M(x)=\sum_{k=1}^K\pi_k\mathcal N(x;\mu_k,\Sigma_k)
$$

å…¶ä¸­ $0\leqslant \pi_k\leqslant 1$ä¸ºæ··åˆç³»æ•°(mixing coefficients)ã€‚

é«˜æ–¯æ··åˆæ¨¡å‹çš„å‚æ•°ä¼°è®¡æ˜¯EMç®—æ³•çš„ä¸€ä¸ªé‡è¦åº”ç”¨ï¼Œéšé©¬å°”ç§‘å¤«æ¨¡å‹çš„éç›‘ç£å­¦ä¹ ä¹Ÿæ˜¯EMç®—æ³•çš„ä¸€ä¸ªé‡è¦åº”ç”¨ã€‚

## EMç®—æ³•

é«˜æ–¯æ··åˆæ¨¡å‹çš„æå¤§ä¼¼ç„¶ä¼°è®¡
$$
\hat\theta=\arg\max_{\theta} \sum_{i=1}^N\log\sum_{k=1}^K\pi_k \mathcal N(x_i;\mu_k,\Sigma_k)
$$
å…¶ä¸­å‚æ•° $\theta_k=(\pi_k,\mu_k,\Sigma_k)$ï¼Œä½¿ç”¨EMç®—æ³•ä¼°è®¡GMMçš„å‚æ•°$\theta$ã€‚

**ä¾ç…§å½“å‰æ¨¡å‹å‚æ•°ï¼Œè®¡ç®—éšå˜é‡åéªŒæ¦‚ç‡**ï¼šç”±è´å¶æ–¯å…¬å¼çŸ¥é“
$$
\begin{aligned}
P(z_i=k|x_i)&=\frac{P(z_i=k)p(x_i|z_i=k)}{p(x_i)} \\
&=\frac{\pi_k\mathcal N(x_i;\mu_k,\Sigma_k)}{\sum_{k=1}^K\pi_k\mathcal N(x_i;\mu_k,\Sigma_k) } \\
&=\gamma_{ik}
\end{aligned}
$$

ä»¤ $\gamma_{ik}$è¡¨ç¤ºç¬¬$i$ä¸ªæ ·æœ¬å±äºç¬¬$k$ä¸ªé«˜æ–¯åˆ†å¸ƒçš„æ¦‚ç‡ã€‚

**E-stepï¼šç¡®å®šQå‡½æ•°**

$$
\begin{aligned}
Q(\theta,\theta^{(t)})&=\sum_{i=1}^N\sum_{k=1}^Kp(z_i=k|x_i,\mu^{(t)},\Sigma^{(t)}) \log p(x_i,z_i=k|\mu,\Sigma)  \\
&=\sum_{i=1}^N\sum_{k=1}^K\gamma_{ik}\log\pi_k\mathcal N(x;\mu_k,\Sigma_k) \\
&=\sum_{i=1}^N\sum_{k=1}^K\gamma_{ik}(\log\pi_k+ \log\mathcal N(x;\mu_k,\Sigma_k) )
\end{aligned}
$$

**M-stepï¼šæ±‚Qå‡½æ•°çš„æå¤§å€¼**

ä¸Šé¢å·²è·å¾—çš„$Q(\theta,\theta^{(t)})$åˆ†åˆ«å¯¹ $\mu_k,\Sigma_k$æ±‚å¯¼å¹¶è®¾ä¸º0ã€‚å¾—åˆ°
$$
\mu_k^{(t+1)}=\frac{\sum_{i=1}^N\gamma_{ik}x_i}{\sum_{i=1}^N\gamma_{ik}} \\
\Sigma_k^{(t+1)}=\frac{\sum_{i=1}^N\gamma_{ik}(x_i-\mu_k^{(t+1)}) (x_i-\mu_k^{(t+1)})^T }{\sum_{i=1}^N\gamma_{ik}}
$$

 å¯ä»¥çœ‹åˆ°ç¬¬$k$ä¸ªé«˜æ–¯åˆ†å¸ƒçš„$\mu_k,\Sigma_k$ æ˜¯æ‰€æœ‰æ ·æœ¬çš„åŠ æƒå¹³å‡ï¼Œå…¶ä¸­æ¯ä¸ªæ ·æœ¬çš„æƒé‡ä¸ºè¯¥æ ·æœ¬å±äºç¬¬$k$ä¸ªé«˜æ–¯åˆ†å¸ƒçš„åéªŒæ¦‚ç‡ $\gamma_{ik}$ã€‚

å¯¹äºæ··åˆç³»æ•° $\pi_k$ï¼Œå› ä¸ºæœ‰é™åˆ¶æ¡ä»¶ï¼Œä½¿ç”¨æ‹‰æ ¼æœ—æ—¥ä¹˜å­æ³•å¯æ±‚å¾—
$$
\pi_k^{(t+1)}=\frac{1}{N}\sum_{i=1}^N\gamma_{ik}
$$

å³ç¬¬$k$ä¸ªé«˜æ–¯åˆ†å¸ƒçš„æ··åˆç³»æ•°æ˜¯å±äº$k$çš„æ ·æœ¬çš„å¹³å‡åéªŒæ¦‚ç‡ï¼Œç”±æ­¤è¿ç”¨EMç®—æ³•èƒ½å¤§å¤§ç®€åŒ–é«˜æ–¯æ··åˆæ¨¡å‹çš„å‚æ•°ä¼°è®¡è¿‡ç¨‹ï¼Œåœ¨ä¸­é—´æ­¥åªéœ€è®¡ç®—$\gamma_{ik}$å°±è¡Œäº†ã€‚

é«˜æ–¯æ··åˆæ¨¡å‹çš„ç®—æ³•æµç¨‹å¦‚ä¸‹å›¾æ‰€ç¤ºï¼š

<img src="https://warehouse-1310574346.cos.ap-shanghai.myqcloud.com/images/ML/GMM_algorithm.png" alt="GMM_algorithm" style="zoom:50%;" />

## é«˜æ–¯æ··åˆèšç±»

é«˜æ–¯æ··åˆèšç±»å‡è®¾æ¯ä¸ªç±»ç°‡ä¸­çš„æ ·æœ¬éƒ½æœä»ä¸€ä¸ªå¤šç»´é«˜æ–¯åˆ†å¸ƒï¼Œé‚£ä¹ˆç©ºé—´ä¸­çš„æ ·æœ¬å¯ä»¥çœ‹ä½œç”±$K$ä¸ªå¤šç»´é«˜æ–¯åˆ†å¸ƒæ··åˆè€Œæˆã€‚

å¼•å…¥éšå˜é‡$z$ æ ‡è®°ç°‡ç±»åˆ«ï¼Œè¿™æ ·å°±å¯ä»¥ä½¿ç”¨é«˜æ–¯æ··åˆæ¨¡å‹
$$
p_M(x)=\sum_{k=1}^K\pi_k\mathcal N(x;\mu_k,\Sigma_k) 
$$

ä½¿ç”¨EMç®—æ³•è¿­ä»£æ±‚è§£ã€‚

ç›¸æ¯”äºK-meansæ›´å…·ä¸€èˆ¬æ€§ï¼Œèƒ½å½¢æˆå„ç§ä¸åŒå¤§å°å’Œå½¢çŠ¶çš„ç°‡ã€‚K-meanså¯è§†ä¸ºé«˜æ–¯æ··åˆèšç±»ä¸­æ¯ä¸ªæ ·æœ¬ä»…æŒ‡æ´¾ç»™ä¸€ä¸ªæ··åˆæˆåˆ†çš„ç‰¹ä¾‹ 
$$
\gamma_{ik}=\begin{cases}
1, & \text{if } k=\arg\min_k\|x_i-\mu_k\|^2\\
0, & \text{otherwise}
\end{cases}
$$
ä¸”å„æ··åˆæˆåˆ†åæ–¹å·®ç›¸ç­‰ï¼Œå‡ä¸ºå¯¹è§’çŸ©é˜µ $\sigma^2 I$ã€‚

# é™„å½•

## Jensen ä¸ç­‰å¼

<img src="https://warehouse-1310574346.cos.ap-shanghai.myqcloud.com/images/ML/Jensen_inequality_0.svg" style="zoom:80%;" />

è‹¥ $f$ æ˜¯å‡¸å‡½æ•°(convex function)ï¼Œå¯¹ä»»æ„çš„  $\lambda\in [0,1]$ï¼Œä¸‹å¼æ’æˆç«‹
$$
f(\lambda x_1+(1-\lambda)x_2)\leqslant \lambda f(x_1)+(1-\lambda)f(x_2)
$$
**Jensen's inequality**å°±æ˜¯ä¸Šå¼çš„æ¨å¹¿ï¼Œè®¾ $f(x)$ ä¸ºå‡¸å‡½æ•°ï¼Œ$\lambda_i\in[0,1],\ \sum_i\lambda_i=1$ ï¼Œåˆ™
$$
f(\sum_i\lambda_ix_i)\leqslant \sum_i\lambda_if(x_i)
$$
è‹¥å°† $\lambda_i$ è§†ä¸ºä¸€ä¸ªæ¦‚ç‡åˆ†å¸ƒï¼Œåˆ™å¯è¡¨ç¤ºä¸ºæœŸæœ›å€¼çš„å½¢å¼
$$
f(\mathbb E[x])\leqslant\mathbb E[f(x)]
$$
<img src="https://warehouse-1310574346.cos.ap-shanghai.myqcloud.com/images/ML/Jensen_inequality.png"  />

æ˜¾ç„¶ï¼Œå¦‚æœ $f$ æ˜¯å‡¹å‡½æ•°(concave function)ï¼Œåˆ™å°†ä¸ç­‰å·åå‘ã€‚

