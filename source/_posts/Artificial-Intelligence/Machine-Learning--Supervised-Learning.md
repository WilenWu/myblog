---
title: 机器学习--监督学习
katex: true
categories:
  - Artificial Intelligence
  - Machine Learning
tags:
  - 机器学习
cover: /img/data-analysis.png
top_img: /img/data-chart3.jpg
abbrlink: 3c1747d9
description:
date:
---



# 回归和分类

## 线性模型

回归分析主要解决以下几个方面的问题：

(1) 确定几个特定的变量之间是否存在相关关系，如果存在的话，找出它们之间合适的数学表达式。  
(2) 根据一个或几个变量的值，预测或控制另一个变量的取值，并且可以知道这种预测能达到什么样的精确度。  
(3) 进行因表分析。例如在对于共同影响一个变量的许多变量(因素)之间，找出哪些是重要因素，哪些是次要因素，这些因素之间又有什么关系等等。  

超参数：数据标准化（归一化、标准化、无处理）、正则化参数、收敛容差、最大迭代次数、求解方法（normal最小二乘法、L-BFGS牛顿法）、惩罚函数（L1、L2）

$Y=βX+error$  （OLS最小二乘法，使ESS最小值）

**Gauss-Markov假设**：$e_i ~ N(0, σ^2)$
(1) $var(e)= σ^2$ , 误差方差=样本方差
(2) $cov( e_i ,e_j )=0 (i  ≠ j)$ , 误差独立性 

回归方程的显著性检验 ($H_0:  β_i=0$)   t检验和F检验 
 :-----  :------  :----- 
 回归平方和 Residual Sum of Squares  $RSS=∑(y_i-mean(Y))^2$ 
 残差平方和 Explained Sum of Squares ESS
 总平方和  Total Sum of Squares  TSS=var(Y)=RSS+ESS
 判定系数   R2= RSS/TSS 
 自由度   degree of freedom  df 
 平方和   sum of square   SS 
 均方 mean  square MS=SS/df 
 F检验    F=MSR/MSE


 方差源   SS  df 
 :-----  :------  :----- 
 回归 RSS 1  
 误差 ESS n-2
 总和 TSS n-1

 ## 广义线性模型

**广义加法模型**：扩展广义线性模型，以纳入任意平滑的函数。这意味着你可以自定义函数y  = f(x)。
**惩罚线性模型**：对惩罚复杂模型的距离添加惩罚项。这往往会使来自相同群体的新数据集预测的更好。
**稳健的线性模型**：对异常值的存在不那么敏感。

- **回归诊断**
正态检验(shapiro)：自变量多重共线性kappa系数(kappa)
线性模型假设的综合验证：若sqrt(vif)>2,存在多重共线性

- **异常值**
离群点(outlierTest)
高杠杆值点（帽子统计量）
强影响点
- **改进措施**
删除观测点
变量变换
正态变换
线性变换
增删变量
- **模型选择**
逐步回归(step/stepAIC)
全子集回归(regsubsets)
- **交叉验证**
通过交叉验证法，我们便可以评价模型的泛化能力。
在k重交叉验证中，样本被分为k个子样本，轮流将k–1个子样本组合作为训练集，另外1个子样本作为保留集。这样会获得k个预测方程，记录k个保留样本的预测表现结果，然后求其平均值。

## 泊松回归

泊松 用一个或多个解释变量预测一个代表频数的响应变量

## Cox 
Cox 比例风险 用一个或多个解释变量预测一个事件（死亡、失败或旧病复发）发生的时间

## 稳健回归

稳健 用一个或多个量化的解释变量预测一个量化的响应变量，能抵御强影响点的干扰

# 分类

经典传统算法包括决策树分类，随机森林分类，线性判别分类，神经网络分类，基于样本的KNN分类，逻辑回归分类，支持向量机分类，朴素贝叶斯分类等。Xgboost

随机森林超参数：决策树个数、最大深度、信息度量方式（gini、entropy）、特征选择方法（auto、all、sqrt、log2、onethird）

Adaboost分类超参数：数据标准化（归一化、标准化、无处理）、分类器个数、最大迭代次数、正则化参数（控制模型复杂度）、收敛容差

 线性判别 Fisher 
 距离判别  mahalanobis 
 贝叶斯分类器  bayes
 逻辑回归   
 
 决策树  
ID3
C4.5
C5.0 Information Gain Information Gain Rate
CART   Gini Index
 
 条件推断树    显著性检验
 随机森林   random forest 
 最近邻算法  KNN 
支持向量机  SVM 
 神经网络  NN 
 卷积神经网络 CNN 空间数据
 RNN时序数据



- 1.1 线性模型
 1.2 线性和二次判别分析
 1.3 内核岭回归
 1.4 支持向量机
 1.5 随机梯度下降
 1.6 最近邻
 1.7 高斯过程
 1.8 交叉分解
 1.9 朴素贝叶斯
 1.10 决策树
 1.11 集成算法
 1.12 多类和多标签算法
 1.13 特征选择
 1.14 半监督学习
 1.15 Isotonic回归
 1.16 概率校准
 1.17 神经网络模型(有监督)

## 类别不平衡问题

针对非平衡的数据集，为了使得模型在这个数据集上学习的效果更加好，需要改变原数据集中结构分布比例的不合理，通过丢弃降低多值对应数量或者复制增加低值对应数量，让不同值下的样本数量大致相同。

平衡方法：random、smote



