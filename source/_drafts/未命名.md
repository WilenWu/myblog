# 入门

## 基本数据管理

变量的重编码

重编码涉及根据同一个变量和/或其他变量的现有值创建新值的过程。举例来说，你可能想：
 将一个连续型变量修改为一组类别值；
 将误编码的值替换为正确值；
 基于一组分数线创建一个表示及格/不及格的变量。

缺失值：缺失值通常以符号NA（Not Available，不可用）表示

R 并不把无限的或者不可能出现的数值标记成缺失值。正无穷和负无穷分别用Inf和–Inf所标记。因此5/0返
回Inf。不可能的值（比如说，sin(Inf)）用NaN符号来标记（not a number，不是一个数）

随机抽样

在数据挖掘和机器学习领域，从更大的数据集中抽样是很常见的做法。举例来说，你可能希
望选择两份随机样本，使用其中一份样本构建预测模型，使用另一份样本验证模型的有效性。
sample()函数能够让你从数据集中（有放回或无放回地）抽取大小为n的一个随机样本。

## 高级数据管理

截尾平均数，即丢弃了最大5%和最小5%的数据和所有缺失值后的算术平均数。

mean(x, trim = 0.05, na.rm=TRUE)

统计函数

| 函数                                                         | 描述 |
| :----------------------------------------------------------- | :--- |
| mean(x) 平均数                                               |      |
| median(x) 中位数                                             |      |
| std(x) 标准差                                                |      |
| var(x) 方差                                                  |      |
| mad(x) 绝对中位差（median absolute deviation）               |      |
| quantile(x,probs) 求分位数。其中x 为待求分位数的数值型向量，probs 为一个由[0,1]之间的概率值组成的数值向量 |      |
| skew 偏度                                                    |      |
| kurt 峰度                                                    |      |
| range(x) 求值域                                              |      |
| sum(x) 求和                                                  |      |
| min(x) 求最小值                                              |      |
| max(x) 求最大值                                              |      |
| scale 为数据对象x 按列进行中心化或标准化                     |      |

数据的标准化
默认情况下，函数scale()对矩阵或数据框的指定列进行均值为0、标准差为1的标准化：
newdata <- scale(mydata)
要对每一列进行任意均值和标准差的标准化，可以使用如下的代码：
newdata <- scale(mydata)*SD + M
其中的M是想要的均值，SD为想要的标准差。

## 基本图形

条形图、箱线图和点图
 饼图和扇形图
 直方图与核密度图

箱线图（又称盒须图）通过绘制连续型变量的五数总括，即最小值、下四分位数（第25百分
位数）、中位数（第50百分位数）、上四分位数（第75百分位数）以及最大值，描述了连续型变量
的分布。箱线图能够显示出可能为离群点（范围±1.5*IQR以外的值，IQR表示四分位距，即上四
分位数与下四分位数的差值）的观测。

![image-20220703230144327](%E6%9C%AA%E5%91%BD%E5%90%8D.assets/image-20220703230144327.png)

小提琴图是箱线图与核密度图的结合。

# 基本统计方法

 描述性统计分析 summary/describe ：最小值、最大值、四分位数和数值型变量的均值，以及因子向量和逻
辑型向量的频数统计。偏度和峰度，变量和观测的数量、缺失值和唯一值的数目。

计算非缺失值的数量、平均数、标准差、中位数、截尾均值、绝对中位差、最小值、最大值、值域、偏度、峰度和平均值的标准误。
 相关系数和协方差
 t检验
 非参数统计

然后我们将学习生成类别型变量的频数表和列联表的方法（以及连带的卡方检验）。

独立性检验
R提供了多种检验类别型变量独立性的方法。本节中描述的三种检验分别为卡方独立性检验 chisq、Fisher精确检验和Cochran-Mantel-Haenszel检验。

相关性的度量
上一节中的显著性检验评估了是否存在充分的证据以拒绝变量间相互独立的原假设。如果可
以拒绝原假设，那么你的兴趣就会自然而然地转向用以衡量相关性强弱的相关性度量。vcd包中
的assocstats()函数可以用来计算二维列联表的phi系数Phi-Coefficient、列联系数Contingency Coeff和Cramer’s V系数。

接下来，我们将考察连续型和有序型变量相关系数的多种形式。

相关系数可以用来描述定量变量之间的关系。相关系数的符号（±）表明关系的方向（正相
关或负相关），其值的大小表示关系的强弱程度（完全不相关时为0，完全相关时为1）。

相关的类型

R可以计算多种相关系数，包括Pearson相关系数、Spearman相关系数、Kendall相关系数、偏
相关系数、多分格（polychoric）相关系数和多系列（polyserial）相关系数。下面让我们依次理
解这些相关系数。

1. Pearson、Spearman和Kendall相关
    Pearson积差相关系数衡量了两个定量变量之间的线性相关程度。Spearman等级相关系数则衡
    量分级定序变量之间的相关程度。Kendall’s Tau相关系数也是一种非参数的等级相关度量。
2. 偏相关
    偏相关是指在控制一个或多个定量变量时，另外两个定量变量之间的相互关系

在计算好相关系数以后，如何对它们进行统计显著性检验呢？常用的原假设为变量间不相关
（即总体的相关系数为0）

最后，我们将转而通过参数检验（t检验）和非参数检验（Mann-Whitney U检验、Kruskal-Wallis检验）方法研究组间差异。

-   独立样本的t 检验：一个针对两组的独立样本t检验可以用于检验两个总体的均值相等的假设。这里假设两组数据是独立的，并且是从正态总体中抽得。

-   非独立样本的t 检验：

    再举个例子，你可能会问：较年轻（14\~24岁）男性的失业率是否比年长（35\~39岁）男性的
    失业率更高？在这种情况下，这两组数据并不独立。你不能说亚拉巴马州的年轻男性和年长男性
    的失业率之间没有关系。在两组的观测之间相关时，你获得的是一个非独立组设计（dependent
    groups design）。前后测设计（pre-post design）或重复测量设计（repeated measures design）同样
    也会产生非独立的组。
    非独立样本的t检验假定组间的差异呈正态分布。

-   多于两组的情况：如果想在多于两个的组之间进行比较，应该怎么做？如果能够假设数据是从正态总体中独
    立抽样而得的，那么你可以使用方差分析（ANOVA）。ANOVA是一套覆盖了许多实验设计和准
    实验设计的综合方法。就这一点来说，它的内容值得单列一章。

组间差异的非参数检验：如果数据无法满足t检验或ANOVA的参数假设，可以转而使用非参数方法。举例来说，若结果变量在本质上就严重偏倚或呈现有序关系，那么你可能会希望使用本节中的方法。

-   两组的比较
    若两组数据独立，可以使用Wilcoxon秩和检验（更广为人知的名字是Mann-Whitney U检验）
    来评估观测是否是从相同的概率分布中抽得的（即，在一个总体中获得更高得分的概率是否比另
    一个总体要大）。调用格式为：
    wilcox.test(y ~ x, data)
    其中的y是数值型变量，而x是一个二分变量

    Wilcoxon符号秩检验是非独立样本t检验的一种非参数替代方法。它适用于两组成对数据和
    无法保证正态性假设的情境。调用格式与Mann-Whitney U检验完全相同

-   多于两组的比较

-   在要比较的组数多于两个时，必须转而寻求其他方法。考虑7.4节中的state.x77数据集。
    它包含了美国各州的人口、收入、文盲率、预期寿命、谋杀率和高中毕业率数据。如果你想比较
    美国四个地区（东北部、南部、中北部和西部）的文盲率，应该怎么做呢？这称为单向设计（one-way
    design），我们可以使用参数或非参数的方法来解决这个问题。
    如果无法满足ANOVA设计的假设，那么可以使用非参数方法来评估组间的差异。如果各组
    独立，则Kruskal-Wallis检验将是一种实用的方法。如果各组不独立（如重复测量设计或随机区组
    设计），那么Friedman检验会更合适。
    Kruskal-Wallis检验的调用格式为：
    kruskal.test(y ~ A, data)
    其中的y是一个数值型结果变量，A是一个拥有两个或更多水平的分组变量（grouping variable）。
    （若有两个水平，则它与Mann-Whitney U检验等价。）而Friedman检验的调用格式为：
    friedman.test(y ~ A | B, data)
    其中的y是数值型结果变量，A是一个分组变量，而B是一个用以认定匹配观测的区组变量（blocking variable）。在以上两例中，data皆为可选参数，它指定了包含这些变量的矩阵或数
    据框。

在本章中，我们评述了R中用于生成统计概要和进行假设检验的函数。我们关注了样本统计
量和频数表、独立性检验和类别型变量的相关性度量、定量变量的相关系数（和连带的显著性检
验）以及两组或更多组定量结果变量的比较。

# 中级方法

## 回归

 拟合并解释线性模型
 检验模型假设
 模型选择

从许多方面来看，回归分析都是统计学的核心。它其实是一个广义的概念，通指那些用一个
或多个预测变量（也称自变量或解释变量）来预测响应变量（也称因变量、效标变量或结果变量）
的方法。通常，回归分析可以用来挑选与响应变量相关的解释变量，可以描述两者的关系，也可
以生成一个等式，通过解释变量来预测响应变量。![image-20220704230425678](%E6%9C%AA%E5%91%BD%E5%90%8D.assets/image-20220704230425678.png)



回归类型 用 途
简单线性 用一个量化的解释变量预测一个量化的响应变量
多项式 用一个量化的解释变量预测一个量化的响应变量，模型的关系是n 阶多项式
多层 用拥有等级结构的数据预测一个响应变量（例如学校中教室里的学生）。也被称为分层模型、嵌套模
型或混合模型
多元线性 用两个或多个量化的解释变量预测一个量化的响应变量
多变量 用一个或多个解释变量预测多个响应变量
Logistic 用一个或多个解释变量预测一个类别型响应变量
泊松 用一个或多个解释变量预测一个代表频数的响应变量
Cox 比例风险 用一个或多个解释变量预测一个事件（死亡、失败或旧病复发）发生的时间
时间序列 对误差项相关的时间序列数据建模
非线性 用一个或多个量化的解释变量预测一个量化的响应变量，不过模型是非线性的
非参数 用一个或多个量化的解释变量预测一个量化的响应变量，模型的形式源自数据形式，不事先设定
稳健 用一个或多个量化的解释变量预测一个量化的响应变量，能抵御强影响点的干扰

在这一章中，我们的重点是普通最小二乘（OLS）回归法，包括简单线性回归、多项式回归
和多元线性回归。OLS回归是现今最常见的统计分析方法，其他回归模型（Logistic回归和泊松回
归）将在第13章介绍。

![image-20220704225209029](%E6%9C%AA%E5%91%BD%E5%90%8D.assets/image-20220704225209029.png)

为了能够恰当地解释OLS模型的系数，数据必须满足以下统计假设。
 正态性 对于固定的自变量值，因变量值成正态分布。
 独立性 Yi值之间相互独立。
 线性 因变量与自变量之间为线性相关。
 同方差性 因变量的方差不随自变量的水平不同而变化。也可称作不变方差，但是说同
方差性感觉上更犀利。
如果违背了以上假设，你的统计显著性检验结果和所得的置信区间就很可能不精确了。注意，
OLS回归还假定自变量是固定的且测量无误差，但在实践中通常都放松了这个假设。

## 方差分析

## 功效分析

## 重抽样和自助法



# 高级方法

## 广义线性模型

## 主成分分析和因子分析

信息过度复杂是多变量数据最大的挑战之一。若数据集有100个变量，如何了解其中所有的
交互关系呢？即使只有20个变量，当试图理解各个变量与其他变量的关系时，也需要考虑190对
相互关系。主成分分析和探索性因子分析是两种用来探索和简化多变量复杂关系的常用方法，它
们之间有联系也有区别。
主成分分析（PCA）是一种数据降维技巧，它能将大量相关变量转化为一组很少的不相关变
量，这些无关变量称为主成分。例如，使用PCA可将30个相关（很可能冗余）的环境变量转化为
5个无关的成分变量，并且尽可能地保留原始数据集的信息。
相对而言，探索性因子分析（EFA）是一系列用来发现一组变量的潜在结构的方法。它通过
寻找一组更小的、潜在的或隐藏的结构来解释已观测到的、显式的变量间的关系。例如，
Harman74.cor包含了24个心理测验间的相互关系，受试对象为145个七年级或八年级的学生。
假使应用EFA来探索该数据，结果表明276个测验间的相互关系可用四个学生能力的潜在因子（语
言能力、反应速度、推理能力和记忆能力）来进行解释。
PCA与EFA模型间的区别参见图14-1。主成分（PC1和PC2）是观测变量（X1到X5）的线性
组合。形成线性组合的权重都是通过最大化各主成分所解释的方差来获得，同时还要保证各主成
分间不相关。
相反，因子（F1和F2）被当作观测变量的结构基础或“原因”，而不是它们的线性组合。代
表观测变量方差的误差（e1到e5）无法用因子来解释。图中的圆圈表示因子和误差无法直接观测，
但是可通过变量间的相互关系推导得到。在本例中，因子间带曲线的箭头表示它们之间有相关性。
在EFA模型中，相关因子是常见的，但并不是必需的。
本章介绍的两种方法都需要大样本来支撑稳定的结果，但是多大样本量才足够也是一个复杂
的问题。目前，数据分析师常使用经验法则：“因子分析需要5～10倍于变量数的样本数。”最近
研究表明，所需样本量依赖于因子数目、与各因子相关联的变量数，以及因子对变量方差的解释程度（Bandalos & Boehm-Kaufman，2009）。我冒险推测一下：如果你有几百个观测，样本量便
已充足。本章中，为保证输出结果（和篇幅原因）可控性，我们将人为设定一些小问题。

![image-20220704233132191](%E6%9C%AA%E5%91%BD%E5%90%8D.assets/image-20220704233132191.png)

## 时间序列

## 聚类分析

## 分类

## 处理缺失数据的高级方法

