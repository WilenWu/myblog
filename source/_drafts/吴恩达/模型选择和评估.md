# Evaluating and choosing models

## Evaluating a model

评估模型：数据集分为训练集(training set)和测试集(test set)。

- 训练集：最小化代价函数拟合模型参数
- 测试集：测试模型表现

以线性回归为例，模型代价函数
$$
J(\mathbf{w},b) = \min_{\substack{\mathbf w,b}}
\frac{1}{2m_\text{train}}\left[
\sum_{i=1}^{m_\text{train}} ( f_{\mathbf{w},b}(\mathbf{x}^{(i)}_\text{train}) - y^{(i)}_\text{train} )^2
+ \lambda\sum_{j=1}^n w_j^2 \right]
$$
测试误差（不包括正则化项）test error
$$
J_\text{test}(\mathbf{w},b) = 
\frac{1}{2m_\text{test}}\sum_{i=1}^{m_\text{test}} ( f_{\mathbf{w},b}(\mathbf{x}^{(i)}_\text{test}) - y^{(i)}_\text{test} )^2
$$
训练误差（不包括正则化项）training error
$$
J_\text{train}(\mathbf{w},b) = 
\frac{1}{2m_\text{train}}\sum_{i=1}^{m_\text{train}} ( f_{\mathbf{w},b}(\mathbf{x}^{(i)}_\text{train}) - y^{(i)}_\text{train} )^2
$$
训练误差不能很好的反映算法的性能以及它的泛化能力（推广到训练集之外的数据）。

## Model selection and cross validation

| data             | % of total | Description                                  |
| ---------------- | :--------: | :------------------------------------------- |
| training         |     60     | 拟合模型参数 $w$ and $b$                     |
| cross-validation |     20     | 选择模型超参数，譬如多项式的阶，神经网络架构 |
| test             |     20     | 评估模型在新数据的表现                       |

交叉验证误差（不包括正则化项）cross validation error
$$
J_\text{cv}(\mathbf{w},b) = 
\frac{1}{2m_\text{cv}}\sum_{i=1}^{m_\text{cv}} ( f_{\mathbf{w},b}(\mathbf{x}^{(i)}_\text{cv}) - y^{(i)}_\text{cv} )^2
$$
![image-20221013231601606](%E6%A8%A1%E5%9E%8B%E9%80%89%E6%8B%A9%E5%92%8C%E8%AF%84%E4%BC%B0.assets/image-20221013231601606.png)

# Bias and variance

## Plot Train, Cross-Validation, Test

多项式模型的阶数选择和bias/variance

![image-20221013233216617](%E6%A8%A1%E5%9E%8B%E9%80%89%E6%8B%A9%E5%92%8C%E8%AF%84%E4%BC%B0.assets/image-20221013233216617.png)

![C2_W3_BiasVarianceDegree](%E6%A8%A1%E5%9E%8B%E9%80%89%E6%8B%A9%E5%92%8C%E8%AF%84%E4%BC%B0.assets/C2_W3_BiasVarianceDegree.png)

## Regularization

正则化参数选择和bias/variance

![image-20221014221457251](%E6%A8%A1%E5%9E%8B%E9%80%89%E6%8B%A9%E5%92%8C%E8%AF%84%E4%BC%B0.assets/image-20221014221457251.png)

![image-20221014222150850](%E6%A8%A1%E5%9E%8B%E9%80%89%E6%8B%A9%E5%92%8C%E8%AF%84%E4%BC%B0.assets/image-20221014222150850.png)

![image-20221014222249456](%E6%A8%A1%E5%9E%8B%E9%80%89%E6%8B%A9%E5%92%8C%E8%AF%84%E4%BC%B0.assets/image-20221014222249456.png)

## high bias or highvariance

如何判断一个算法有高偏差或高方差

事实证明，在判断误差是否高的时候，建立基准水平（baseline）通常是有用的。基线水平指的是对学习算法的误差水平有个合理的期待。建立基线水平的常见方法

- 衡量人类在这项任务上的表现。
- 竞争对手的算法表现
- 经验猜测

## Learning curves

学习曲线（Learning curves）是一种帮你了解学习算法性能如何的方式，曲线随着经验的数量发生变化。经验数量指的是算法所拥有的训练样本数。

![image-20221014225955004](%E6%A8%A1%E5%9E%8B%E9%80%89%E6%8B%A9%E5%92%8C%E8%AF%84%E4%BC%B0.assets/image-20221014225955004.png)

- 当训练集越来越大时，你学到的模型更好，交叉验证误差也会减少。
- 当你有非常少的训练样本时，你可以很容易地得到零或很小的训练误差。当你有一个更大的训练集时，模型很难完美的拟合所有的训练样本。

![image-20221014230037222](%E6%A8%A1%E5%9E%8B%E9%80%89%E6%8B%A9%E5%92%8C%E8%AF%84%E4%BC%B0.assets/image-20221014230037222.png)



![image-20221014230102072](%E6%A8%A1%E5%9E%8B%E9%80%89%E6%8B%A9%E5%92%8C%E8%AF%84%E4%BC%B0.assets/image-20221014230102072.png)

# 机器学习开发进程

## Error analysis

误差分析的要点是，手动检查一组算法错误分类的样本。通常分析完后，下一步要做什么的灵感就来了。有时无法分析也会告诉你，某种误差十分罕见，不值得花费过多时间来修复。

 ## Adding data

- 数据增强 Data augmentation
- 数据合成 Data synthesis

## Transfer learning: using data from a different task

迁移学习：可以让你用来自不同任务的数据帮助你解决当前任务。

1. 下载带有参数的神经网络，这些参数已经在大型数据集上预先训练过了，且与算法有相同的输入类型（图像，语音，文本等）。
2. 再根据自己的数据进一步训练或微调神经网络。

![image-20221016224821163](%E6%A8%A1%E5%9E%8B%E9%80%89%E6%8B%A9%E5%92%8C%E8%AF%84%E4%BC%B0.assets/image-20221016224821163.png)

## Full cycle of a machine learning project

![image-20221016225458400](%E6%A8%A1%E5%9E%8B%E9%80%89%E6%8B%A9%E5%92%8C%E8%AF%84%E4%BC%B0.assets/image-20221016225458400.png)

MLOps (machine learning operations)

# Skewed datasets

数据倾斜

![image-20221016232308197](%E6%A8%A1%E5%9E%8B%E9%80%89%E6%8B%A9%E5%92%8C%E8%AF%84%E4%BC%B0.assets/image-20221016232308197.png)

![image-20221016232348430](%E6%A8%A1%E5%9E%8B%E9%80%89%E6%8B%A9%E5%92%8C%E8%AF%84%E4%BC%B0.assets/image-20221016232348430.png)